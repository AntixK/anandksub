<!doctype html><html lang=en><head><meta charset=UTF-8><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=stylesheet href=/_css/ak.css><link rel=icon href=/assets/icons/favicon.ico type=image/x-icon><title></title></head><body><header><h1><a href=/ >Anand K Subramanian</a><br><br></h1></header><nav class=navbar><span><a href=/blog/ >Blog</a><span class=vl></span></span><span><a href=/notes/ >Notes</a> <span class=vl></span></span><span><a href=/art/ >Art</a> <span class=vl></span></span><span><a href=/CV>CV</a> <span class=vl></span></span><span><a href=/tags>Tags</a></nav><main><br><br><h1>Posts about #code</h1><table><colgroup><col span=1 style=width:30%;></colgroup><tr><td><p class=date>26 Sep 2024<p></td><td><h3 style=margin-top:0.5rem;><a href=/blog/Reg_To_Cls>Classification to Regression and Back</a></h3><p class=tags>A trick to convert classification labels to regression targets and back.</p><p class=tags><span class=pound>#</span>math <span class=pound>#</span>ml <span class=pound>#</span>code </p></td></tr><tr><td><p class=date>02 Aug 2024<p></td><td><h3 style=margin-top:0.5rem;><a href=/blog/Autodiff_Combinatorial_Solver>Differentiating Straight-Through Combinatorial Solvers</a></h3><p class=tags>Naive zeroth-order gradient estimation for backpropagating through combinatorial solvers.</p><p class=tags><span class=pound>#</span>math <span class=pound>#</span>ml <span class=pound>#</span>code <span class=pound>#</span>gradient <span class=pound>#</span>deep-learning <span class=pound>#</span>combinatorial-solver </p></td></tr><tr><td><p class=date>12 Jan 2024<p></td><td><h3 style=margin-top:0.5rem;><a href=/blog/GMM_Mahalanobis>Extending Mahalanobis Distance to Gaussian Mixtures</a></h3><p class=tags>A simple generalization of Mahalanobis distance to Gaussian Mixture Models (GMMs).</p><p class=tags><span class=pound>#</span>math <span class=pound>#</span>ml <span class=pound>#</span>code </p></td></tr><tr><td><p class=date>29 Aug 2022<p></td><td><h3 style=margin-top:0.5rem;><a href=/blog/improving_ransac>Improving the RANSAC Algorithm</a></h3><p class=tags>Discussion about the MAGSAC algorithm, addressing a crucial hyperparameter selection issue for the RANSAC algorithm.</p><p class=tags><span class=pound>#</span>math <span class=pound>#</span>ml <span class=pound>#</span>code <span class=pound>#</span>jax </p></td></tr><tr><td><p class=date>18 Jul 2022<p></td><td><h3 style=margin-top:0.5rem;><a href=/blog/A_Detour_to_the_Imaginary>A Detour to the Imaginary has its Benefits</a></h3><p class=tags>Two examples of using complex numbers for real-function optimization.</p><p class=tags><span class=pound>#</span>numerics <span class=pound>#</span>math <span class=pound>#</span>ml <span class=pound>#</span>gradient <span class=pound>#</span>code <span class=pound>#</span>python </p></td></tr><tr><td><p class=date>29 Jun 2022<p></td><td><h3 style=margin-top:0.5rem;><a href=/blog/Back_gradient_trick>The Back-Gradient Trick</a></h3><p class=tags>Stochastic Gradient Descent can be (kind of) reversed and can be used to compute gradients with respect to its hyperparameters.</p><p class=tags><span class=pound>#</span>math <span class=pound>#</span>ml <span class=pound>#</span>gradient <span class=pound>#</span>graph <span class=pound>#</span>code <span class=pound>#</span>jax <span class=pound>#</span>deep-learning </p></td></tr><tr><td><p class=date>31 May 2022<p></td><td><h3 style=margin-top:0.5rem;><a href=/blog/parallel_kalman>Parallelizing Kalman Filters</a></h3><p class=tags>The associative property of Kalman (Bayesian) filters can yield a parallel algorithm in O(log N). </p><p class=tags><span class=pound>#</span>math <span class=pound>#</span>ml <span class=pound>#</span>parallel <span class=pound>#</span>code <span class=pound>#</span>jax </p></td></tr><tr><td><p class=date>23 Sep 2021<p></td><td><h3 style=margin-top:0.5rem;><a href=/blog/fast-sample-covariance>Fast Sample-Covariance Computation for Multidimensional Arrays</a></h3><p class=tags>A quick discussion and a vectorized Python implementation for the computation of sample covariance matrices for multi-dimensional arrays.</p><p class=tags><span class=pound>#</span>math <span class=pound>#</span>ml <span class=pound>#</span>code </p></td></tr><tr><td><p class=date>30 Aug 2021<p></td><td><h3 style=margin-top:0.5rem;><a href=/blog/asymmetric-numeral-systems>Asymmetric Numeral Systems</a></h3><p class=tags>A tutorial on the lossless Asymmetric Numeral Systems (ANS) coding commonly used in image compression. </p><p class=tags><span class=pound>#</span>math <span class=pound>#</span>ml <span class=pound>#</span>information-theory <span class=pound>#</span>code </p></td></tr><tr><td><p class=date>02 Oct 2019<p></td><td><h3 style=margin-top:0.5rem;><a href=/blog/Subset_GP_VI>Variational Gaussian Process Training using Subset of Data</a></h3><p class=tags>Scaling up Gaussian Processes with the Subset of Data technique.</p><p class=tags><span class=pound>#</span>math <span class=pound>#</span>ml <span class=pound>#</span>code <span class=pound>#</span>gaussian-process <span class=pound>#</span>vi </p></td></tr></table></main><div style="font-size: 1.2rem; font-family: 'Overpass'; color: var(--c-4); text-align: center; margin-top: 6em; border-width: 75%; border-top: 1px solid var(--c-4); padding-top: 2em; margin-bottom: 4em;"> &copy; 2024 Anand K Subramanian <span class=vl></span><a href=/license>License</a> <span class=vl></span><a href=/design>Design</a> <span class=vl></span> Built with Kutti <span style="color: #e25555; font-size: 24px;">&hearts;</span></div></body></html>