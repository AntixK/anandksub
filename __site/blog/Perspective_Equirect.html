<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width, initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><script>
    document.addEventListener("DOMContentLoaded", function () {
      renderMathInElement(document.body, {
        throwOnError: false,
        // output: "html",
        // customised options
        // • auto-render specific keys, e.g.:
        delimiters: [
          { left: '$$', right: '$$', display: true }, // block
          { left: '$', right: '$', display: false }, // Inline
          { left: "\begin{align}", right: "\end{align}", display: true }, // block
          { left: "\begin{aligned}", right: "\end{aligned}", display: true }, // block
        ],
        ignoredTags: [
          "pre",
          "code",
          "script",
          "style",
        ],
        macros: {
          "\\A": "\\mathbb{A}",
          "\\B": "\\mathbb{B}",
          "\\C": "\\mathbb{C}",
          "\\D": "\\mathbb{D}",
          "\\E": "\\mathbb{E}",
          "\\F": "\\mathbb{F}",
          "\\G": "\\mathbb{G}",
          "\\H": "\\mathbb{H}",
          "\\I": "\\mathbb{I}",
          "\\J": "\\mathbb{J}",
          "\\K": "\\mathbb{K}",
          "\\L": "\\mathbb{L}",
          "\\M": "\\mathbb{M}",
          "\\N": "\\mathbb{N}",
          "\\O": "\\mathbb{O}",
          "\\P": "\\mathbb{P}",
          "\\Q": "\\mathbb{Q}",
          "\\R": "\\mathbb{R}",
          "\\S": "\\mathbb{S}",
          "\\T": "\\mathbb{T}",
          "\\U": "\\mathbb{U}",
          "\\V": "\\mathbb{V}",
          "\\W": "\\mathbb{W}",
          "\\X": "\\mathbb{X}",
          "\\Y": "\\mathbb{Y}",
          "\\Z": "\\mathbb{Z}",

          "\\fA": "\\mathcal{A}",
          "\\fB": "\\mathcal{B}",
          "\\fC": "\\mathcal{C}",
          "\\fD": "\\mathcal{D}",
          "\\fE": "\\mathcal{E}",
          "\\fF": "\\mathcal{F}",
          "\\fG": "\\mathcal{G}",
          "\\fH": "\\mathcal{H}",
          "\\fI": "\\mathcal{I}",
          "\\fJ": "\\mathcal{J}",
          "\\fK": "\\mathcal{K}",
          "\\fL": "\\mathcal{L}",
          "\\fM": "\\mathcal{M}",
          "\\fN": "\\mathcal{N}",
          "\\fO": "\\mathcal{O}",
          "\\fP": "\\mathcal{P}",
          "\\fQ": "\\mathcal{Q}",
          "\\fR": "\\mathcal{R}",
          "\\fS": "\\mathcal{S}",
          "\\fT": "\\mathcal{T}",
          "\\fU": "\\mathcal{U}",
          "\\fV": "\\mathcal{V}",
          "\\fW": "\\mathcal{W}",
          "\\fX": "\\mathcal{X}",
          "\\fY": "\\mathcal{Y}",
          "\\fZ": "\\mathcal{Z}",

          "\\x": "\\times",
          "\\vA": "\\mathbf{A}",
          "\\vB": "\\mathbf{B}",
          "\\vC": "\\mathbf{C}",
          "\\vD": "\\mathbf{D}",
          "\\vE": "\\mathbf{E}",
          "\\vF": "\\mathbf{F}",
          "\\vG": "\\mathbf{G}",
          "\\vH": "\\mathbf{H}",
          "\\vI": "\\mathbf{I}",
          "\\vJ": "\\mathbf{J}",
          "\\vK": "\\mathbf{K}",
          "\\vL": "\\mathbf{L}",
          "\\vM": "\\mathbf{M}",
          "\\vN": "\\mathbf{N}",
          "\\vO": "\\mathbf{O}",
          "\\vP": "\\mathbf{P}",
          "\\vQ": "\\mathbf{Q}",
          "\\vR": "\\mathbf{R}",
          "\\vS": "\\mathbf{S}",
          "\\vT": "\\mathbf{T}",
          "\\vU": "\\mathbf{U}",
          "\\vV": "\\mathbf{V}",
          "\\vW": "\\mathbf{W}",
          "\\vX": "\\mathbf{X}",
          "\\vY": "\\mathbf{Y}",
          "\\vZ": "\\mathbf{Z}",

          "\\va": "\\mathbf{a}",
          "\\vb": "\\mathbf{b}",
          "\\vc": "\\mathbf{c}",
          "\\vd": "\\mathbf{d}",
          "\\ve": "\\mathbf{e}",
          "\\vf": "\\mathbf{f}",
          "\\vg": "\\mathbf{g}",
          "\\vh": "\\mathbf{h}",
          "\\vi": "\\mathbf{i}",
          "\\vj": "\\mathbf{j}",
          "\\vk": "\\mathbf{k}",
          "\\vl": "\\mathbf{l}",
          "\\vl": "\\mathbf{l}",
          "\\vm": "\\mathbf{m}",
          "\\vn": "\\mathbf{n}",
          "\\vo": "\\mathbf{o}",
          "\\vp": "\\mathbf{p}",
          "\\vq": "\\mathbf{q}",
          "\\vr": "\\mathbf{r}",
          "\\vs": "\\mathbf{s}",
          "\\vt": "\\mathbf{t}",
          "\\vu": "\\mathbf{u}",
          "\\vv": "\\mathbf{v}",
          "\\vw": "\\mathbf{w}",
          "\\vx": "\\mathbf{x}",
          "\\vy": "\\mathbf{y}",
          "\\vz": "\\mathbf{z}",

          "\\vmu": "\\boldsymbol \\mu",
          "\\vnu": "\\boldsymbol \\nu",
          "\\veps": "\\boldsymbol \\epsilon",
          "\\vtheta": "\\boldsymbol \\theta",
          "\\vomega": "\\boldsymbol \\omega",
          "\\vlambda": "\\boldsymbol \\lambda",
          "\\vzero": "\\mathbf{0}",
          "\\vone": "\\mathbf{1}",
          "\argmin": "\mathop{\mathrm{argmin}} \;",
          "\argmax": "\mathop{\mathrm{argmax}} \;",
          "\\KL": "\\mathop{D_{\\mathrm{KL}}} \\;",

        },
        globalGroup: true,
      });
    });
  </script><link rel=stylesheet href=/_libs/katex/katex.min.css><script defer src=/_libs/algorithm/algotype.js crossorigin=anonymous></script><script defer src=/_libs/katex/katex.min.js crossorigin=anonymous>
  </script></script><script defer src=/_libs/katex/auto-render.min.js crossorigin=anonymous onload=renderMathInElement(document.body);></script><link rel=stylesheet href=/_css/ak.css><link rel=icon href=/assets/icons/favicon.ico type=image/x-icon><title>Converting Between Perspective and Equirectangular Projections</title></head><body><header><h1><a href=/ >Anand K Subramanian</a><br><br></h1></header><nav class=navbar><span><a href=/blog/ >Blog</a><span class=vl></span></span><span><a href=/notes/ >Notes</a> <span class=vl></span></span><span><a href=/art/ >Art</a> <span class=vl></span></span><span><a href=/CV>CV</a> <span class=vl></span></span><span><a href=/tags>Tags</a></nav><p class=tags><img class=icon-image src=/assets/icons/bookmark.svg alt=clock-icon>&ensp;<span class=pound>#</span>math <span class=pound>#</span>geometric-projection <span class=pound>#</span>image-processing <span class=pound>#</span>code </p><p class=tags><img class=icon-image src=/assets/icons/calendar.svg alt=clock-icon>&ensp;5 December 2024 </p><p class=tags><img class=icon-image src=/assets/icons/timer.svg alt=clock-icon>&ensp;9 mins </p><h1>Converting Between Perspective and Equirectangular Projections</h1><p class=tldr>Inverting the common procedure of converting equirectangular images to perspective images.</p><main><p> </p><h3>Perspective Projection</h3><p>Perpsective projections are what you get when you take a photo with your camera. Objects that are further away from the camera appear smaller and all the lines appead to project toward <em>vanishing points</em> (i.e. where the parallel lines seem to converge).</p><p>Difference between rectilinear projection and perspective projection.</p><p>Note about fisheyelens.</p><p>What is gnomonic projection?</p><p>Recall that the Pinhole Camera model (bet used for a perspective projection), where some real-world point $p$ with coordinates $(x, y,z)$ is projected onto the image plane at $(u, v)$ as</p><p>$$ \begin{aligned} \begin{bmatrix} u \\ v \\ 1 \end{bmatrix} &amp;= \begin{bmatrix} f_x &amp; 0 &amp; 0 &amp; c_x \\ 0 &amp; f_y &amp; 0 &amp; c_y \\ 0 &amp; 0 &amp; 1 &amp; 0 \end{bmatrix} \begin{bmatrix} r_{11} &amp; r_{12} &amp; r_{13} &amp; t_1 \\ r_{21} &amp; r_{22} &amp; r_{23} &amp; t_2 \\ r_{31} &amp; r_{32} &amp; r_{33} &amp; t_3 \end{bmatrix} \begin{bmatrix} x \\ y \\ z \\ 1 \end{bmatrix}\\ &amp;= KR \begin{bmatrix} x \\ y \\ z \\ 1 \end{bmatrix} \end{aligned} $$</p><p>Where $K$ is the <em>intrinsic</em> camera matrix, $R$ is the <em>extrinsic</em> camera matrix, $f_x, f_y$ are the focal lengths of the camera, $c_x, c_y$ are the principal points, and $t_1, t_2, t_3$ are the translation components <sup id=fnref:cam><a class=fnref href=#fndef:cam>[1]</a></sup>. Therefore, given the matrices $K$ and $R$, we can convert between pixel coordinates and the world coordinates.</p><pre><code class=language-python>def camera_to_world(points: np.ndarray, K: np.ndarray, R:np.ndarray) -&gt; np.ndarray:
    """

    Transforms the given 3D points from camera coordinates to world coordinates

    Args:
        points (np.ndarray): 3D points in homogeneous camera coordinates
        K (np.ndarray): 3x3 matrix representing the intrinsic camera matrix
        R (np.ndarray): 3x3 matrix representing the extrinsic camera matrix (rotation)

    Returns:
        world_points (np.ndarray): 3D points in world coordinates

    """

    K_inv = np.linalg.inv(K)

    world_points = (points @ K_inv.T) @ R.T
    return world_points


def world_to_camera(points: np.ndarray, K: np.ndarray, R:np.ndarray) -&gt; np.ndarray:
    """

    Transforms the given 3D points from world coordinates to camera coordinates

    Args:
        points (np.ndarray): 3D points in world coordinates
        K (np.ndarray): 3x3 matrix representing the intrinsic camera matrix
        R (np.ndarray): 3x3 matrix representing the extrinsic camera matrix (rotation + translation)

    Returns:
        camera_points (np.ndarray): 3D points in camera coordinates
    """

    # Add translation to the rotation matrix
    # As of now, the translation is zero.
    R = np.hstack([R, np.array([[0,0,0]], np.float32).T])

    camera_points = (points @ R.T) @ K.T
    return camera_points
</code></pre><p>To get the camera matrix $K$ from a given image, we only need two parameters - the field-of-view (FOV) and the image dimensions $(W, H)$.</p><pre><code class=language-python>def get_camera_matrix(FOV: float, width: int, height: int) -&gt; np.ndarray:
    """

    Computes the intrinsic camera matrix from the given camera
    field of view (FOV) and image/window dimensions.

    Args:
        FOV (float): Field of view in radians
        width (int): Image/window width
        height (int): Image/window height

    Returns:
        K (np.ndarray): 3x3 matrix representing the intrinsic camera matrix
    """

    f = 0.5 * width / np.tan(0.5 * FOV)
    cx = (width) / 2.0
    cy = (height) / 2.0

    K = np.array([
            [f, 0, cx],
            [0, f, cy],
            [0, 0, 1]]).astype(np.float32)

    return K
</code></pre><pre><code class=language-python>def get_extrinsic_matrix(THETA:float, PHI:float):

    # Default
    elevation_vector = np.array([0.0, THETA, 0.0], np.float32)
    azimuth_vector = np.array([PHI, 0.0, 0.0], np.float32)

    # Use Rodrigues' formula to convert the
    # angle vector (simulatenous) to rotation matrix
    R1, _ = cv2.Rodrigues(elevation_vector)
    R2, _ = cv2.Rodrigues(np.dot(R1, azimuth_vector))

    R = R2 @ R1
    return R
</code></pre><h3>Equirectangular Projection</h3><p>Mapping from 3D world coordinates $p$ to 2D equirectangular coordinates $(x_{eq}, y_{eq})$ is a two-step procedure. Since the Equirectangular projection is a projection of a sphere unto a 2D surface, we first convert the 3D world coordinates to <em>spherical coordinates</em> $(\theta, \phi)$ as</p><p>$$ (\theta, \phi) = \left ( \text{atan2} (x, z), \arcsin \left (\frac{y}{\rho} \right ) \right ) $$</p><p>Where $\rho = \sqrt{x^2 + y^2 + z^2}$. Mention the link with latitude and longitude.</p><pre><code class=language-python>def cartesian_to_spherical(points: np.ndarray) -&gt; np.ndarray:
    """
    Converts the given 3D points from cartesian coordinates to spherical coordinates

    Args:
        points (np.ndarray): 3D points in cartesian coordinates

    Returns:
        sp_coords (np.ndarray): 3D points in spherical coordinates (rho, theta, phi)
    """

    assert points.shape[-1] == 3, "Input should have 3 (X, Y, Z) components"

    x, y, z = points[..., 0], points[..., 1], points[..., 2]

    # Distance of points from the origin
    rho = np.linalg.norm(points, axis=-1)

    # Normalize the points on the sphere of the above radius
    # to get the points on the unit sphere
    x /= rho
    y /= rho
    z /= rho

    # Elevation angle (aka latitude)
    phi = np.arcsin(y)

    # Azimuthal angle (aka longitude)
    theta = np.arctan2(x, z)

    # return np.stack([rho, theta, phi], axis=-1)
    return np.stack([rho, theta, phi]).T


def spherical_to_cartesian(sp_coords: np.ndarray) -&gt; np.ndarray:
    """
    Converts the given 3D points from spherical coordinates to cartesian coordinates

    Args:
        sp_coords (np.ndarray): 3D points in spherical coordinates (rho, theta, phi)

    Returns:
        points (np.ndarray): 3D points in cartesian coordinates
    """

    assert sp_coords.shape[-1] == 3, "Input should have 3 (rho, phi, theta) components"

    rho = sp_coords[..., 0]
    theta = sp_coords[..., 1]
    phi = sp_coords[..., 2]

    x = rho * np.cos(phi) * np.sin(theta)
    y = rho * np.sin(phi)
    z = rho * np.cos(phi) * np.cos(theta)

    return np.stack([x, y, z], axis=-1)
</code></pre><p>Next, the above spherical cooridinates are mapped to the 2D equirectangular coordinates $(x_{eq}, y_{eq})$ as</p><p>$$ \begin{aligned} x_{eq} &amp;= \left ( \frac{\theta }{ 2\pi} + 0.5 \right ) W \\ y_{eq} &amp;= \left ( \frac{\phi}{\pi} \right ) H \end{aligned} $$</p><p>explain the 0.5.</p><p>Where $W$ and $H$ are the width and height of the equirectangular image respectively. As evident from the above formula, the resultant mapping to the 2D plane is a distorted one, with the poles of the sphere being stretched out. However, compared to other similar cylindrical projections like the Mercator or the Lambert's, the equirectangular is the simplest as the latitude and longitudes are directly mapped to the 2D plane and as such</p><pre><code class=language-python>def spherical2equirect(sp_coords: np.ndarray,
                       width: int,
                       height: int)-&gt; np.ndarray:
    """
    Args:
        sp_coords (np.ndarray): Spherical coordinates (theta, phi, rho)
        width (int): Width of the equirectangular image
        height (int): Height of the equirectangular image

    Returns:
        np.ndarray: Equirectangular coordinates (x, y)
    """

    rho, theta, phi = sp_coords[..., 0], sp_coords[..., 1], sp_coords[..., 2]
    x = (theta / (2 * np.pi) + 0.5) * (width)
    y = (phi / (np.pi) + 0.5) * (height)

    return np.stack([x, y], dtype=np.float32).transpose(2, 1, 0) # (width, height, 2)
</code></pre><p>reference: https://marksmath.org/classes/common/MapProjection.pdf</p><p>reference: https://hugin.sourceforge.io/docs/manual/Projections.html</p><p>Where is equirectagnular projection actually useful? VR? Panoramic Images?</p><p>The equirectangular projection is widely used for spherical panorama viewers.</p><pre><code class=language-python>def Equirec2Perspec(img:np.ndarray,
                    FOV: float,
                    THETA: float,
                    PHI: float,
                    height: int,
                    width:int) -&gt; np.ndarray:
    """
    Args:
        img (np.ndarray): Equirectangular image
        FOV (float): Field of view in degrees
        THETA (float): Elevation angle in degrees
        PHI (float): Azimuthal angle in degrees
        height (int): Height of the perspective image
        width (int): Width of the perspective

    Returns:
        Perspective image
    """

    # Convert the angles to radians
    FOV = np.deg2rad(FOV)
    THETA = np.deg2rad(THETA)
    PHI = np.deg2rad(PHI)

    img_height, img_width = img.shape[:2]
    # Compute the intrinsic camera matrix
    K = get_camera_matrix(FOV, width, height)

    # Compute the extrinsic matrix
    R = get_extrinsic_matrix(THETA, PHI)

    # Generate the image grid
    x, y = np.meshgrid(np.arange(width), np.arange(height))

    # Convert the image grid to homogeneous coordinates
    z = np.ones_like(x)
    xyz = np.concatenate([x[..., None], y[..., None], z[..., None]], axis=-1)

    # Convert the image grid to world coordinates
    world_coords = camera_to_world(xyz, K, R)

    # Convert the world coordinates to spherical coordinates
    sp_coords = cartesian_to_spherical(world_coords)

    # Convert the spherical coordinates to image coordinates
    XY = spherical2equirect(sp_coords, img_width, img_height)

    # Generate the perspective image
    persp = cv2.remap(img, XY[..., 0], XY[..., 1], cv2.INTER_CUBIC, borderMode=cv2.BORDER_WRAP)


    return persp
</code></pre><p>Once we have the above forward function, it is simple to invert the process to get the perspective image from the equirectangular image.</p><pre><code class=language-python>
def Perspec2Equirec(img: np.ndarray,
                    FOV: float,
                    THETA:float,
                    PHI:float,
                    height:int,
                    width:int) -&gt; np.ndarray:
  """

  Args:
          img (np.ndarray): Perspective image
          FOV (float): Field of view in degrees
          THETA (float): Elevation angle in degrees
          PHI (float): Azimuthal angle in degrees
          height (int): Height of the output equirectangular image
          width (int): Width of the output equirectangular image

  Returns:
          Equirectangular image (np.ndarray)
  """

  # Convert the angles to radians
  FOV = np.deg2rad(FOV)
  THETA = np.deg2rad(THETA)
  PHI = np.deg2rad(PHI)

  img_height, img_width = img.shape[:2]

  K = get_camera_matrix(FOV, img_width, img_height)
  R = get_extrinsic_matrix(THETA, PHI)

  # Invert the extrinsic matrix (its orthogonal)
  R = R.T

  # Generate the grid points for the equirectangular image
  u, v = np.meshgrid(np.linspace(0,1,width), np.linspace(0,1,height))

  # Map the above equirect coordinates to spherical coordinates
  theta = 2 * np.pi * (u - 0.5)
  phi = np.pi * (v - 0.5)

  # The above block is equivalent to
  # theta, phi = np.meshgrid(np.linspace(-np.pi, np.pi, width), np.linspace(-np.pi/2, np.pi/2, height))

  # Construct the spherical Coordinates
  sp_coords = np.stack([np.ones_like(theta), theta, phi], axis=-1)

  # Convert the spherical coordinates to cartesian (world) coordinates
  coords = spherical_to_cartesian(sp_coords).astype(np.float32)

  # Make the world coords homogeneous
  coords = np.append(coords, np.ones_like(coords[..., :1]), axis=-1)

  # Map the world coordinates to camera coordinates
  camera_coords = world_to_camera(coords, K, R)

  # Project and x, y coordinates to the image plane and normalize
  uv = camera_coords[..., :2] / camera_coords[..., 2:3]
  uv = uv.astype(np.float32)

  # Mask out the points that are "behind" the camera
  mask = camera_coords[..., 2] &gt; 0

  mask *= np.where((uv[..., 0] &gt;= 0)&amp;
          (uv[...,0] &lt; img_width)&amp;
          (uv[...,1] &gt;= 0)&amp;
          (uv[...,1] &lt; img_height), True, False)

  equirec = cv2.remap(img, uv[..., 0], uv[...,1], cv2.INTER_CUBIC, borderMode=cv2.BORDER_WRAP)

  equirec *= mask[..., None]
  return equirec

</code></pre><hr><p><table class=fndef id=fndef:cam><tr><td class=fndef-backref><a href=#fnref:cam>[1]</a></td><td class=fndef-content>A couple of good references for camera model and their history can be found <a href=https://cvgl.stanford.edu/teaching/cs231a_winter1415/lecture/lecture2_camera_models_note.pdf>here</a> and <a href=https://www.cse.psu.edu/~rtc12/CSE486/lecture12.pdf>here</a>.</td></tr></table></p></main><div style="font-size:1.2rem; font-family: 'Overpass'; color: var(--c-4); text-align: center; margin-top: 6em; border-width: 75%; border-top: 1px solid var(--c-4); padding-top: 2em; margin-bottom: 4em;"> &copy; 2025 Anand K Subramanian <span class=vl></span><a href=/license>License</a> <span class=vl></span><a href=/design>Design</a> <span class=vl></span> Built with Kutti <span style="color: #e25555; font-size: 24px;">&hearts;</span></div><script src=/_libs/highlight/highlight.min.js></script><script>hljs.highlightAll(); hljs.configure({ tabReplace: '    ' });</script><link rel=stylesheet href=/_libs/highlight/decaf.css><script src=/_libs/clipboard/clipboard.min.js></script><script>
    (function () {

      // Get the elements.
      // - the 'pre' element.
      // - the 'div' with the 'paste-content' id.

      var pre = document.getElementsByTagName('pre');

      // Add a copy button in the 'pre' element.
      // which only has the className of 'language-'.

      for (var i = 0; i < pre.length; i++) {
        var isLanguage = pre[i].children[0].className.indexOf('language-');

        if (isLanguage === 0) {
          var button = document.createElement('button');
          button.className = 'copy-button';
          button.textContent = 'Copy';

          pre[i].appendChild(button);
        }
      };

      // Run Clipboard

      var copyCode = new Clipboard('.copy-button', {
        target: function (trigger) {
          return trigger.previousElementSibling;
        }
      });

      // On success:
      // - Change the "Copy" text to "Copied".
      // - Swap it to "Copy" in 2s.
      // - Lead user to the "contenteditable" area with Velocity scroll.

      copyCode.on('success', function (event) {
        event.clearSelection();
        event.trigger.textContent = 'Copied';
        window.setTimeout(function () {
          event.trigger.textContent = 'Copy';
        }, 2000);

      });

      // On error (Safari):
      // - Change the  "Press Ctrl+C to copy"
      // - Swap it to "Copy" in 2s.

      copyCode.on('error', function (event) {
        event.trigger.textContent = 'Press "Ctrl + C" to copy';
        window.setTimeout(function () {
          event.trigger.textContent = 'Copy';
        }, 5000);
      });

    })();
  </script></body></html>