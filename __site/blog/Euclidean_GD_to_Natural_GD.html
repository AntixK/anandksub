<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width, initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><script>
    document.addEventListener("DOMContentLoaded", function () {
      renderMathInElement(document.body, {
        throwOnError: false,
        // output: "html",
        // customised options
        // • auto-render specific keys, e.g.:
        delimiters: [
          { left: '$$', right: '$$', display: true }, // block
          { left: '$', right: '$', display: false }, // Inline
          { left: "\begin{align}", right: "\end{align}", display: true }, // block
          { left: "\begin{aligned}", right: "\end{aligned}", display: true }, // block
        ],
        ignoredTags: [
          "pre",
          "code",
          "script",
          "style",
        ],
        macros: {
          "\\A": "\\mathbb{A}",
          "\\B": "\\mathbb{B}",
          "\\C": "\\mathbb{C}",
          "\\D": "\\mathbb{D}",
          "\\E": "\\mathbb{E}",
          "\\F": "\\mathbb{F}",
          "\\G": "\\mathbb{G}",
          "\\H": "\\mathbb{H}",
          "\\I": "\\mathbb{I}",
          "\\J": "\\mathbb{J}",
          "\\K": "\\mathbb{K}",
          "\\L": "\\mathbb{L}",
          "\\M": "\\mathbb{M}",
          "\\N": "\\mathbb{N}",
          "\\O": "\\mathbb{O}",
          "\\P": "\\mathbb{P}",
          "\\Q": "\\mathbb{Q}",
          "\\R": "\\mathbb{R}",
          "\\S": "\\mathbb{S}",
          "\\T": "\\mathbb{T}",
          "\\U": "\\mathbb{U}",
          "\\V": "\\mathbb{V}",
          "\\W": "\\mathbb{W}",
          "\\X": "\\mathbb{X}",
          "\\Y": "\\mathbb{Y}",
          "\\Z": "\\mathbb{Z}",

          "\\fA": "\\mathcal{A}",
          "\\fB": "\\mathcal{B}",
          "\\fC": "\\mathcal{C}",
          "\\fD": "\\mathcal{D}",
          "\\fE": "\\mathcal{E}",
          "\\fF": "\\mathcal{F}",
          "\\fG": "\\mathcal{G}",
          "\\fH": "\\mathcal{H}",
          "\\fI": "\\mathcal{I}",
          "\\fJ": "\\mathcal{J}",
          "\\fK": "\\mathcal{K}",
          "\\fL": "\\mathcal{L}",
          "\\fM": "\\mathcal{M}",
          "\\fN": "\\mathcal{N}",
          "\\fO": "\\mathcal{O}",
          "\\fP": "\\mathcal{P}",
          "\\fQ": "\\mathcal{Q}",
          "\\fR": "\\mathcal{R}",
          "\\fS": "\\mathcal{S}",
          "\\fT": "\\mathcal{T}",
          "\\fU": "\\mathcal{U}",
          "\\fV": "\\mathcal{V}",
          "\\fW": "\\mathcal{W}",
          "\\fX": "\\mathcal{X}",
          "\\fY": "\\mathcal{Y}",
          "\\fZ": "\\mathcal{Z}",

          "\\x": "\\times",
          "\\vA": "\\mathbf{A}",
          "\\vB": "\\mathbf{B}",
          "\\vC": "\\mathbf{C}",
          "\\vD": "\\mathbf{D}",
          "\\vE": "\\mathbf{E}",
          "\\vF": "\\mathbf{F}",
          "\\vG": "\\mathbf{G}",
          "\\vH": "\\mathbf{H}",
          "\\vI": "\\mathbf{I}",
          "\\vJ": "\\mathbf{J}",
          "\\vK": "\\mathbf{K}",
          "\\vL": "\\mathbf{L}",
          "\\vM": "\\mathbf{M}",
          "\\vN": "\\mathbf{N}",
          "\\vO": "\\mathbf{O}",
          "\\vP": "\\mathbf{P}",
          "\\vQ": "\\mathbf{Q}",
          "\\vR": "\\mathbf{R}",
          "\\vS": "\\mathbf{S}",
          "\\vT": "\\mathbf{T}",
          "\\vU": "\\mathbf{U}",
          "\\vV": "\\mathbf{V}",
          "\\vW": "\\mathbf{W}",
          "\\vX": "\\mathbf{X}",
          "\\vY": "\\mathbf{Y}",
          "\\vZ": "\\mathbf{Z}",

          "\\va": "\\mathbf{a}",
          "\\vb": "\\mathbf{b}",
          "\\vc": "\\mathbf{c}",
          "\\vd": "\\mathbf{d}",
          "\\ve": "\\mathbf{e}",
          "\\vf": "\\mathbf{f}",
          "\\vg": "\\mathbf{g}",
          "\\vh": "\\mathbf{h}",
          "\\vi": "\\mathbf{i}",
          "\\vj": "\\mathbf{j}",
          "\\vk": "\\mathbf{k}",
          "\\vl": "\\mathbf{l}",
          "\\vl": "\\mathbf{l}",
          "\\vm": "\\mathbf{m}",
          "\\vn": "\\mathbf{n}",
          "\\vo": "\\mathbf{o}",
          "\\vp": "\\mathbf{p}",
          "\\vq": "\\mathbf{q}",
          "\\vr": "\\mathbf{r}",
          "\\vs": "\\mathbf{s}",
          "\\vt": "\\mathbf{t}",
          "\\vu": "\\mathbf{u}",
          "\\vv": "\\mathbf{v}",
          "\\vw": "\\mathbf{w}",
          "\\vx": "\\mathbf{x}",
          "\\vy": "\\mathbf{y}",
          "\\vz": "\\mathbf{z}",

          "\\vmu": "\\boldsymbol \\mu",
          "\\vnu": "\\boldsymbol \\nu",
          "\\veps": "\\boldsymbol \\epsilon",
          "\\vtheta": "\\boldsymbol \\theta",
          "\\vomega": "\\boldsymbol \\omega",
          "\\vlambda": "\\boldsymbol \\lambda",
          "\\vzero": "\\mathbf{0}",
          "\\vone": "\\mathbf{1}",
          "\argmin": "\mathop{\mathrm{argmin}} \;",
          "\argmax": "\mathop{\mathrm{argmax}} \;",
          "\\KL": "\\mathop{D_{\\mathrm{KL}}} \\;",

        },
        globalGroup: true,
      });
    });
  </script><link rel=stylesheet href=/_libs/katex/katex.min.css><script defer src=/_libs/algorithm/algotype.js crossorigin=anonymous></script><script defer src=/_libs/katex/katex.min.js crossorigin=anonymous>
  </script></script><script defer src=/_libs/katex/auto-render.min.js crossorigin=anonymous onload=renderMathInElement(document.body);></script><link rel=stylesheet href=/_css/ak.css><link rel=icon href=/assets/icons/favicon.ico type=image/x-icon><title>Segue from Euclidean Gradient Descent to Natural Gradient Descent</title></head><body><header><h1><a href=/ >Anand K Subramanian</a><br><br></h1></header><nav class=navbar><span><a href=/blog/ >Blog</a><span class=vl></span></span><span><a href=/notes/ >Notes</a> <span class=vl></span></span><span><a href=/art/ >Art</a> <span class=vl></span></span><span><a href=/CV>CV</a> <span class=vl></span></span><span><a href=/tags>Tags</a></nav><p class=tags><img class=icon-image src=/assets/icons/bookmark.svg alt=clock-icon>&ensp;<span class=pound>#</span>math <span class=pound>#</span>ml <span class=pound>#</span>gradient <span class=pound>#</span>natural-gradient <span class=pound>#</span>deep-learning </p><p class=tags><img class=icon-image src=/assets/icons/calendar.svg alt=clock-icon>&ensp;18 August 2019 </p><p class=tags><img class=icon-image src=/assets/icons/timer.svg alt=clock-icon>&ensp;5 mins </p><h1>Segue from Euclidean Gradient Descent to Natural Gradient Descent</h1><p class=tldr>A slight change in SGD formulation, in terms of maximization of local approximation, leads to an interesting general connection to NGD via mirror descent.</p><main><p>  Natural Gradient descent has recently been gaining quite a significant amount of attention (and rightly so!) since it was originally proposed by Shun-ichi Amari way back in the late 1990s. Especially the Approximate Bayesian Inference group at RIKEN-AIP, Tokyo, have successfully applied<sup id=fnref:3><a class=fnref href=#fndef:3>[1]</a></sup> Natural gradients to a range of complex Bayesian models.</p><p>In this post, I shall discuss one simple yet interesting segue from gradient descent in Euclidean space to Natural gradient descent. In an <a href=https://antixk.github.io/blog/nat-grad-exp-fam/ >earlier blog post</a>, we discussed the relationship between gradient descent and natural gradient descent for the exponential family of distributions. In this post, we shall see a more generic connection between them, leveraging the results of Raskutti et. al <sup id=fnref:2><a class=fnref href=#fndef:2>[2]</a></sup>.</p><p>Consider the standard SGD update with respect to the learning parameters $\boldsymbol{\theta}$ at time step $t+1$ in Euclidean space as follows</p><p>$$ \begin{aligned} \boldsymbol \theta_{t+1} = \boldsymbol \theta_t + \beta_t \hat{\nabla}_{\boldsymbol{\theta}}L(\boldsymbol{\theta}_t) \end{aligned} $$</p><p>Where $\hat{\nabla}_{\boldsymbol{\theta}}L(\boldsymbol{\theta}_t)$ is the gradient of the loss function with respect to the parameters and $\beta_t$ is the current learning rate. The above SGD update can be reformulated as a local approximation maximization as follows -</p><p>$$ \begin{aligned} \boldsymbol{\theta}_{t+1} = \underset{\boldsymbol{\theta}\in \Theta}{\mathsf{argmax}} \big\langle \boldsymbol \theta, \hat{\nabla}_{\boldsymbol{\theta}}L(\boldsymbol{\theta}_t) \big \rangle - \frac{1}{2\beta_t} \| \boldsymbol{\theta} - \boldsymbol{\theta}_t\|_2^2 \end{aligned} $$</p><p>From a probabilistic perspective, $\boldsymbol \theta$ is the <em>natural parameter</em> of the modelling distribution. In other words, the model tries to learn the data using the distribution $q(\boldsymbol{\theta})$, whose natural parameters $\boldsymbol{\theta}$ are learned during training. Intuitively, the above equation is simply a constraint maximization problem with a constraint that $\|\boldsymbol{\theta} - \boldsymbol{\theta_t}\|_2$ is zero, and $-\frac{1}{\beta_t}$ is the Lagrange multiplier. SGD update given above, therefore, works in the natural parameter space. Note that the Euclidean norm in the second term, indicating that the descent happens in the Euclidean space.</p><p>Now, The natural gradient update is given by</p><p>$$ \begin{aligned} \boldsymbol \theta_{t+1} = \boldsymbol \theta_t + \frac{1}{\beta_t} \mathbf{F}(\boldsymbol{\theta})^{-1}\hat{\nabla}_{\boldsymbol{\theta}}L(\boldsymbol{\theta}_t) \end{aligned} $$</p><p>Where $\mathbf{F}$ is the Fisher Information matrix. The gradient scaled by the corresponding Fisher information is called as the natural gradient.</p><h4>Proximity Function</h4><p>In equation (2), the Euclidean norm is actually a <em>proximity function</em> that measures the discrepancy of the loss function and its linear approximation with respect to the local geometry. This is quadratic term is exact for convex landscapes while provides a somewhat decent approximation for others.</p><p>From a different perspective, the proximity function can also be viewed as a prior belief about the loss landscape. Second order methods like that of Newton's, directly employ the Hessian to obtain the local quadratic curvature (which is still an approximation) and scale the gradients accordingly. Natural gradients, on the other hand, use the Riemannian curvature tensor (Represented here by the Fisher Information) to capture the exact local geometry of the landscape.</p><h3>The Connection</h3><p>We rewrite the above maximization problem in terms of the expectation(mean) parameters of the distribution $q$, and use the KL divergence for the proximity function, to get the following mirror descent formulation.</p><p>$$ \begin{aligned} \boldsymbol{\mu}_{t+1} = \underset{\boldsymbol{\mu}\in M}{\mathsf{argmax}} \big\langle \boldsymbol \mu, \hat{\nabla}_{\boldsymbol{\mu}}L(\boldsymbol{\theta}_t) \big \rangle - \frac{1}{\beta_t} KL(q_m(\boldsymbol{\theta})\|q_m(\boldsymbol \theta_t)) \end{aligned} $$</p><p>Instead of performing the parameter update on the natural parameter space, we are updating its <em>dual</em> - the expectation parameters. The now, interesting the connection is that the above mirror descent update on the mean parameters, is equivalent to performing natural gradient update on the natural parameters.</p><h4>Why Mirror Descent?</h4><p>Mirror descent is a framework that accounts for the geometry of the optimization landscape. It is a generalized framework that incorporates almost all optimization algorithms and over high dimensions. For example, in high dimensions, the local linear or quadratic approximation of the loss surface usually fails. Therefore, it is desirable to employ the actual local geometry of the loss landscape, and mirror descent framework provides an elegant way to exactly that! The second term in the above two maximization formulations (a.k.a proximity function) $-$ the Euclidean norm and the KL divergence $-$ represents the movement of the parameters taking into account the geometry of the landscape.</p><h4>Why does this work?</h4><p>The main idea behind the above connection is that the Fisher information is the Hessian of the KL divergence between two distributions $q(\boldsymbol{\theta})$ and $q(\boldsymbol{\theta}')$. The proof is quite elaborate and I shall discuss in a subsequent post. Moreover, we can simply rewrite the natural gradient update in equation (3), as a maximization problem as follows -</p><p>$$ \begin{aligned} \boldsymbol{\theta}_{t+1} = \underset{\boldsymbol{\theta}\in \Theta}{\mathsf{argmax}} \big\langle \boldsymbol \theta, \hat{\nabla}_{\boldsymbol{\theta}}L(\boldsymbol{\theta}_t) \big \rangle- \frac{1}{\beta_t} KL(q_m(\boldsymbol{\theta})\|q_m(\boldsymbol \theta_t)) \end{aligned} $$</p><p>Now, it is clear that there is nothing special about the mirror descent in the mean parameter space. We could have as well said that it is a mirror descent in the natural parameter space. However, the connection is important as provides a much simpler way to perform natural gradient descent in the mean parameter space.</p><p>Recall the connection between the natural gradients and the Fisher information discussed in a <a href=https://anandksub.dev/blog/Natural_gradient_exp_family>previous blog post</a>.</p><p>$$ \begin{aligned} \mathbf{F}(\boldsymbol{\theta})^{-1}\nabla_{\boldsymbol{\theta}}L(\boldsymbol{\theta}) = \nabla_{\boldsymbol{\mu}}L(\boldsymbol{\mu}_t) \end{aligned} $$</p><p>That is, the natural gradient with respect to $\boldsymbol{\theta}$ is simply the gradient of the loss function with respect to the mean parameters $\boldsymbol{\mu}$. In other words, by combining with equation (4), the natural gradient descent is essentially gradient descent in mean parameter space. Now, with the help of the above equation, we can directly perform fast natural gradient descent by the following update</p><p>$$ \begin{aligned} \boldsymbol \theta_{t+1} = \boldsymbol \theta_t + \beta_t \hat{\nabla}_{\boldsymbol{\mu}}L(\boldsymbol{\mu}_t) \end{aligned} $$</p><h3>Summing Up</h3><br><style type=text/css>
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-0lax{text-align:left;vertical-align:top}
</style><table class=tg><thead><tr><th class=tg-0lax></th><th class=tg-0lax>Gradient Descent</th><th class=tg-0lax>Natural Gradient Descent</th></tr></thead><tbody><tr><td class=tg-0lax><b>Geometry</b></td><td class=tg-0lax>Euclidean Geometry</td><td class=tg-0lax>Statistical Manifold (Riemannian Geometry</td></tr><tr><td class=tg-0lax><b>Proximity Function</b></td><td class=tg-0lax>Euclidean Norm</td><td class=tg-0lax>Divergence (Ex. KL Divergence)</td></tr><tr><td class=tg-0lax><b>Gradient parameters</b></td><td class=tg-0lax>Natural parameters $\boldsymbol{\theta}$ </td><td class=tg-0lax>Mean parameters $\boldsymbol{\mu}$</td></tr></tbody></table><br><br><br><div class=important><p><strong>Equivalence</strong> : Natural Gradient in $\boldsymbol{\theta}$ $\Leftrightarrow$ Gradient in $\boldsymbol{\mu}$</p></div><hr><p><table class=fndef id=fndef:3><tr><td class=fndef-backref><a href=#fnref:3>[1]</a></td><td class=fndef-content>Khan, Mohammad Emtiyaz, et al. "Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam." arXiv preprint arXiv:1806.04854 (2018).</td></tr></table></p><p><table class=fndef id=fndef:2><tr><td class=fndef-backref><a href=#fnref:2>[2]</a></td><td class=fndef-content>Raskutti, Garvesh, and Sayan Mukherjee. "The information geometry of mirror descent." IEEE Transactions on Information Theory 61.3 (2015): 1451-1457.</td></tr></table></p></main><div style="font-size:1.2rem; font-family: 'Overpass'; color: var(--c-4); text-align: center; margin-top: 6em; border-width: 75%; border-top: 1px solid var(--c-4); padding-top: 2em; margin-bottom: 4em;"> &copy; 2024 Anand K Subramanian <span class=vl></span><a href=/license>License</a> <span class=vl></span><a href=/design>Design</a> <span class=vl></span> Built with Kutti <span style="color: #e25555; font-size: 24px;">&hearts;</span></div></body></html>