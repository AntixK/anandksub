<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width, initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><script>
    document.addEventListener("DOMContentLoaded", function () {
      renderMathInElement(document.body, {
        throwOnError: false,
        // output: "html",
        // customised options
        // • auto-render specific keys, e.g.:
        delimiters: [
          { left: '$$', right: '$$', display: true }, // block
          { left: '$', right: '$', display: false }, // Inline
          { left: "\begin{align}", right: "\end{align}", display: true }, // block
          { left: "\begin{aligned}", right: "\end{aligned}", display: true }, // block
        ],
        ignoredTags: [
          "pre",
          "code",
          "script",
          "style",
        ],
        macros: {
          "\\A": "\\mathbb{A}",
          "\\B": "\\mathbb{B}",
          "\\C": "\\mathbb{C}",
          "\\D": "\\mathbb{D}",
          "\\E": "\\mathbb{E}",
          "\\F": "\\mathbb{F}",
          "\\G": "\\mathbb{G}",
          "\\H": "\\mathbb{H}",
          "\\I": "\\mathbb{I}",
          "\\J": "\\mathbb{J}",
          "\\K": "\\mathbb{K}",
          "\\L": "\\mathbb{L}",
          "\\M": "\\mathbb{M}",
          "\\N": "\\mathbb{N}",
          "\\O": "\\mathbb{O}",
          "\\P": "\\mathbb{P}",
          "\\Q": "\\mathbb{Q}",
          "\\R": "\\mathbb{R}",
          "\\S": "\\mathbb{S}",
          "\\T": "\\mathbb{T}",
          "\\U": "\\mathbb{U}",
          "\\V": "\\mathbb{V}",
          "\\W": "\\mathbb{W}",
          "\\X": "\\mathbb{X}",
          "\\Y": "\\mathbb{Y}",
          "\\Z": "\\mathbb{Z}",

          "\\fA": "\\mathcal{A}",
          "\\fB": "\\mathcal{B}",
          "\\fC": "\\mathcal{C}",
          "\\fD": "\\mathcal{D}",
          "\\fE": "\\mathcal{E}",
          "\\fF": "\\mathcal{F}",
          "\\fG": "\\mathcal{G}",
          "\\fH": "\\mathcal{H}",
          "\\fI": "\\mathcal{I}",
          "\\fJ": "\\mathcal{J}",
          "\\fK": "\\mathcal{K}",
          "\\fL": "\\mathcal{L}",
          "\\fM": "\\mathcal{M}",
          "\\fN": "\\mathcal{N}",
          "\\fO": "\\mathcal{O}",
          "\\fP": "\\mathcal{P}",
          "\\fQ": "\\mathcal{Q}",
          "\\fR": "\\mathcal{R}",
          "\\fS": "\\mathcal{S}",
          "\\fT": "\\mathcal{T}",
          "\\fU": "\\mathcal{U}",
          "\\fV": "\\mathcal{V}",
          "\\fW": "\\mathcal{W}",
          "\\fX": "\\mathcal{X}",
          "\\fY": "\\mathcal{Y}",
          "\\fZ": "\\mathcal{Z}",

          "\\x": "\\times",
          "\\vA": "\\mathbf{A}",
          "\\vB": "\\mathbf{B}",
          "\\vC": "\\mathbf{C}",
          "\\vD": "\\mathbf{D}",
          "\\vE": "\\mathbf{E}",
          "\\vF": "\\mathbf{F}",
          "\\vG": "\\mathbf{G}",
          "\\vH": "\\mathbf{H}",
          "\\vI": "\\mathbf{I}",
          "\\vJ": "\\mathbf{J}",
          "\\vK": "\\mathbf{K}",
          "\\vL": "\\mathbf{L}",
          "\\vM": "\\mathbf{M}",
          "\\vN": "\\mathbf{N}",
          "\\vO": "\\mathbf{O}",
          "\\vP": "\\mathbf{P}",
          "\\vQ": "\\mathbf{Q}",
          "\\vR": "\\mathbf{R}",
          "\\vS": "\\mathbf{S}",
          "\\vT": "\\mathbf{T}",
          "\\vU": "\\mathbf{U}",
          "\\vV": "\\mathbf{V}",
          "\\vW": "\\mathbf{W}",
          "\\vX": "\\mathbf{X}",
          "\\vY": "\\mathbf{Y}",
          "\\vZ": "\\mathbf{Z}",

          "\\va": "\\mathbf{a}",
          "\\vb": "\\mathbf{b}",
          "\\vc": "\\mathbf{c}",
          "\\vd": "\\mathbf{d}",
          "\\ve": "\\mathbf{e}",
          "\\vf": "\\mathbf{f}",
          "\\vg": "\\mathbf{g}",
          "\\vh": "\\mathbf{h}",
          "\\vi": "\\mathbf{i}",
          "\\vj": "\\mathbf{j}",
          "\\vk": "\\mathbf{k}",
          "\\vl": "\\mathbf{l}",
          "\\vl": "\\mathbf{l}",
          "\\vm": "\\mathbf{m}",
          "\\vn": "\\mathbf{n}",
          "\\vo": "\\mathbf{o}",
          "\\vp": "\\mathbf{p}",
          "\\vq": "\\mathbf{q}",
          "\\vr": "\\mathbf{r}",
          "\\vs": "\\mathbf{s}",
          "\\vt": "\\mathbf{t}",
          "\\vu": "\\mathbf{u}",
          "\\vv": "\\mathbf{v}",
          "\\vw": "\\mathbf{w}",
          "\\vx": "\\mathbf{x}",
          "\\vy": "\\mathbf{y}",
          "\\vz": "\\mathbf{z}",

          "\\vmu": "\\boldsymbol \\mu",
          "\\vnu": "\\boldsymbol \\nu",
          "\\veps": "\\boldsymbol \\epsilon",
          "\\vtheta": "\\boldsymbol \\theta",
          "\\vomega": "\\boldsymbol \\omega",
          "\\vlambda": "\\boldsymbol \\lambda",
          "\\vzero": "\\mathbf{0}",
          "\\vone": "\\mathbf{1}",
          "\argmin": "\mathop{\mathrm{argmin}} \;",
          "\argmax": "\mathop{\mathrm{argmax}} \;",
          "\\KL": "\\mathop{D_{\\mathrm{KL}}} \\;",

        },
        globalGroup: true,
      });
    });
  </script><link rel=stylesheet href=/_libs/katex/katex.min.css><script defer src=/_libs/katex/katex.min.js crossorigin=anonymous></script><script defer src=/_libs/katex/auto-render.min.js crossorigin=anonymous onload=renderMathInElement(document.body);></script><link rel=stylesheet href=/_css/ak.css><link rel=icon href=/assets/icons/favicon.ico type=image/x-icon><title>A Detour to the Imaginary has its Benefits</title></head><body><header><h1><a href=/ >Anand K Subramanian</a><br><br></h1></header><nav class=navbar><span><a href=/blog/ >Blog</a><span class=vl></span></span><span><a href=/notes/ >Notes</a> <span class=vl></span></span><span><a href=/art/ >Art</a> <span class=vl></span></span><span><a href=/CV>CV</a> <span class=vl></span></span><span><a href=/tags>Tags</a></nav><p class=tags><img class=icon-image src=/assets/icons/bookmark.svg alt=clock-icon>&ensp;<span class=pound>#</span>numerics <span class=pound>#</span>math <span class=pound>#</span>ml <span class=pound>#</span>gradient <span class=pound>#</span>code <span class=pound>#</span>python </p><p class=tags><img class=icon-image src=/assets/icons/calendar.svg alt=clock-icon>&ensp;18 July 2022 </p><p class=tags><img class=icon-image src=/assets/icons/timer.svg alt=clock-icon>&ensp;11 mins </p><h1>A Detour to the Imaginary has its Benefits</h1><p class=tldr>Two examples of using complex numbers for real-function optimization.</p><main><p>  Complex numbers often popup in strange and unexpected places. This cliché has become second only to $\pi$. However, these clichès are indeed warranted. Besides from them popping up unexpectedly, one can also try to employ them in unexpected ways. Below are two such examples where leveraging complex numbers yields interesting and compact results.</p><h2>1 : Complex Step Numerical Differentiation</h2><p>  The common naïve method for differentiating a function $f: \R \to \R$ is given by the forward difference formula $$ f'(x) = \frac{f(x + h) - f(x)}{h} + \fO(h) $$<a id=eq:fwd_diff class=anchor></a></p><p>where $h$ is the real finite difference interval and $\fO(h)$ is the truncation error (from the full Taylor series of $f(x)$). The above method is not accurate or computationally efficient, but it is quite easy to implement.</p><p>The common issue with implementing the above formula is the <em>step-size dilemma</em>, the tradeoff between choosing a small step size $h$ and a small resultant error. To reduce the truncation error, $h$ should be small as possible; however, too small a step size would result in numerical errors like subtractive cancellation, deeming the result inaccurate.</p><p>A slight numerical improvement to the equation <span class=eqref>(<a href=#eq:fwd_diff>1</a>)</span> is the central difference formula. $$ f'(x) = \frac{f(x + h/2) - f(x - h/2)}{h} + \fO(h^2/4) $$<a id=eq:cent_diff class=anchor></a></p><p>Notice the truncation error is now dependent upon $h^2$ rather than $h$. For $h \ll 0$, this is a considerable improvement<sup id=fnref:1><a class=fnref href=#fndef:1>[1]</a></sup>.However, the plague of subtractive cancellation still persists.</p><p>Can we do any better? Enter complex numbers.</p><p>Consider an analytic function $f: \C \to \C$ over complex variable $z = x + iy$ as $f = u + iv $. Then, the Cauchy-Riemann equations are given by - $$ \begin{aligned} \frac{du}{dx} &amp;= \frac{dv}{dy}\\ \frac{du}{dy} &amp;= -\frac{dv}{dx}\\ \end{aligned} $$ Expanding the first equation by equation <span class=eqref>(<a href=#eq:fwd_diff>1</a>)</span>, we get $$ \frac{du}{dx} = \lim_{h \to 0} \frac{v(x + i(y + h)) - v(x + iy)}{h} $$ where $h$ is real. Now, the class of functions that we are interested in are real, so $y=0, v(x) = 0$ and $f(x) = u(x)$. Substituting these in the above equation, we get</p><p>$$ \begin{aligned} \frac{df}{dx} &amp;= \lim_{h \to 0} \frac{\Im[f(x + ih)]}{h}\\ f'(x) &amp;\approx \frac{\Im[f(x + ih)]}{h} \end{aligned} $$<a id=eq:com_diff class=anchor></a></p><p>Where $\Im$ is the imaginary part. Voilà! We have now eliminated subtraction from the differentiation formula! To evaluate how good the above formula is, we need to find the truncation error.</p><p>$$ \begin{aligned} f(x + ih) &amp;= f(x) + ihf'(x) - h^2 \frac{f^{''}(x)}{2!} + \cdots \\ f'(x) &amp;= \frac{\Im[f(x + ih)]}{h} + h^2 \frac{f^{''}(x)}{2!} + \cdots \\ &amp;= \frac{\Im[f(x + ih)]}{h} + \fO(h^2) \\ \end{aligned} $$</p><p>We have now obtained a numerical differentiation formula for a real function that does not suffer from subtractive cancellation, and has a significantly low truncation error. Owing to this, the above formula admits extremely low values of $h$, even to the machine precision $\epsilon$.</p><img style=width:100%;min-width:300px; src=/media/post_images/cdiff.svg alt="Complex step numerical differentiation comparison."><p>Implementing complex-step differentiation is extremely simple too.</p><pre><code class=language-python>import numpy as np

def complex_step_diff(func, x, h):
    z = complex(x, h)
    return np.imag(func(z) / h)
</code></pre><h3>Comparison with Automatic Differentiation</h3><p>The equation <span class=eqref>(<a href=#eq:com_diff>5</a>)</span> and forward-mode automatic differentiations bears a close relationship. Consider the function $f(x_1, x_2) = x_1^2 \sin(x_2)$. The differential $df/d x_1$ can be computed by forward-mode autodiff and complex-step differentiation as follows.</p><p>$$ \begin{aligned} \Delta x_1 &amp;= 1 &amp;&amp;&amp; h_1 &amp;= 1e-20 \\ \Delta x_2 &amp;= 0 &amp;&amp;&amp; h_2 &amp;= 0 \\ f(x_1, x_2) &amp;= x_1^2 \sin(x_2) &amp;&amp;&amp; \bar{f} &amp;= (x_1 + ih_1)^2 \sin(x_2 + ih_2) \\ df/dx_1 &amp;= 2x_1\sin(x_2)\Delta x_1 + x_1^2\cos(x_2)\Delta x_2 &amp;&amp;&amp; \bar{f} &amp;= (x_1^2 - h_1^2 +i2x_1h_1) \\ &amp; &amp;&amp;&amp; &amp;(\sin(x_2)\cosh(h_2) + i\cos(x_2) \sinh(h_2)) \\ df/dx_1 &amp;= 2x_1\sin(x_2) &amp;&amp;&amp; df/dx_1 &amp;= \Im[\bar{f}]/h_1 = 2x_1 \sin(x_2)\cosh(h_2) + \\ &amp; &amp;&amp;&amp; &amp; \cos(x_2) \sinh(h_2) (x_1^2 - h_1^2) / h_1 \\ &amp; &amp;&amp;&amp; &amp;= 2x_1 \sin(x_2) \end{aligned} $$<a id=eq:comp_cs_ad class=anchor></a></p><p>Both methods yield the same result. The perturbations $\Delta x$ are stored in a separate variables in autodiff, while they are stored in the imaginary parts in complex-step differentiation. Compared to the forward (and reverse) mode autodiff that computes gradients based on perturbations at the level of machine precision<sup id=fnref:2><a class=fnref href=#fndef:2>[2]</a></sup>, complex-step too can produce equally accurate gradients at the level of machine precision (refer to above figure).</p><p>  However, complex-step differentiation is not applicable in cases where there is a complicated control flow in the computational graph of the function $f$. These control flows often result in discontinuities. Complex-step differentiation requires specific tricks to handle each of these cases<sup id=fnref:3><a class=fnref href=#fndef:3>[3]</a></sup> while autodiff handles them in a more rigorous manner. Moreover, complex-step always performs additional computations compared to autodiff as shown in equation <span class=eqref>(<a href=#eq:comp_cs_ad>7</a>)</span>. For these reasons, autodiff should still be preferred.</p><hr><h2>2 : Complex Momentum Stochastic Gradient Descent</h2><p>  Consider the classical Stochastic Gradient Descent (SGD) algorithm with momentum as shown below.</p><p>$$ \begin{aligned} \upsilon_{t+1} &amp;= \nu \, \upsilon_t - \nabla_{\theta} f \\ \theta_{t+1} &amp;= \theta_t + \alpha\, \upsilon_{t+1} \end{aligned} $$<a id=eq:sgd class=anchor></a></p><p>Where $f(\theta)$ is the function whose parameter $\theta$ is being optimized at step $t+1$, $v$ is the velocity accelerated by the momentum $\nu$, and $\alpha$ is the learning rate. Usually, the momentum value is set to be positive ($\nu \geq 0$). However, one can argue that the momentum value should actually depend upon the loss landscape, just like the learning rate $\alpha$. A lot of effort has been put into automatically adapting the learning rate $\alpha$ based on the local loss landscape. SGD modifications like RMSProp, and Adam<sup id=fnref:adam><a class=fnref href=#fndef:adam>[4]</a></sup>, apart from a range of learning rate schedulers have been developed to make the optimization work on a variety of different objectives and loss landscapes.</p><p>One may extend the idea to momentum as well. Indeed, it has been shown that first-order method like SGD with positive momentum do not converge for adversarial problems like GANs. GANs, given their dueling networks design, represent a zero-sum game. One player - the Generator $G: \vz \to \vx$ $-$ maximizes their chance of fooling the Discriminator $D: \vx \to \R$, while the Discriminator minimizes their chance of getting fooled. This is mathematically represented as</p><p>$$ \underset{G \sim \fG}{\min} \; \underset{D \sim \fD}{\max}\ V(G, D) $$<a id=eq:gan_loss class=anchor></a></p><p>Where $V$ is the objective function that captures the dueling dynamic. In its general form, it is written as $ V(G, D) = \E[f(D(\vx))] + \E[f(-D(G(\vz)))]$<sup id=fnref:nag><a class=fnref href=#fndef:nag>[5]</a></sup>, where $f$ is some function.</p><img style=width:100%;min-width:300px; src=/media/post_images/dirac_gan.webp alt="Comparison of various values for momentum in SGD for GANs"><p class="caption-text ">Behold, the eye!</p><p>The above figure shows the training trajectories of Dirac GAN<sup id=fnref:dirac><a class=fnref href=#fndef:dirac>[6]</a></sup> with learning rate $\alpha = 0.01$ across various momentum values - no momentum($\nu=0$), positive, negative, and even complex momentum. Intuitively, if positive momentum is akin to a heavy ball that accelerates the gradient descent, negative momentum is like friction that slows it down<sup id=fnref:negmom><a class=fnref href=#fndef:negmom>[7]</a></sup>. From the above figure, the training converges for all momentum values <em>except</em> for a positive-valued momentum ($\nu = 0.9$).</p><p>If positive momentum values work well for non-adversarial problems, and negative momentum works for adversarial problems, what if we use a complex valued momentum $\nu$? That way, we may obtain a more generic first-order optimizer. That exactly what Lorraine et. al. did<sup id=fnref:complexsgd><a class=fnref href=#fndef:complexsgd>[8]</a></sup>. We can directly modify the equation <span class=eqref>(<a href=#eq:sgd>8</a>)</span> for a complex0valued momentum as</p><p>$$ \begin{aligned} \Re\{\upsilon_{t+1}\} &amp;= \Re \{\nu \, \upsilon_t - \nabla_{\theta} f \} \\ \Im\{\upsilon_{t+1}\} &amp;= \Im \{\nu \, \upsilon_t \} \\ w_{t+1} &amp;= w_t + \Re \{\alpha\, \upsilon_{t+1}\} \end{aligned} $$<a id=eq:complex-sgd class=anchor></a></p><p>Where $\Re$ and $\Im$ are the real and imaginary parts respectively.</p><video autoplay muted loop><source src=/media/post_images/gan_opt.mp4 type=video/mp4;>> </video><p class="caption-text ">2D GAN on Toy data with complex-momentum</p><p>In practice, complex-momentum SGD requires 2 momentum buffers (for the real and imaginary parts) and is quite easy to implement.</p><pre><code class=language-python>import torch

class ComplexSGD(torch.optim.Optimizer):
    """
    SGD with Complex-valued Momentum
    """

    def __init__(self,
                 params,
                 lr:float,
                 momentum:torch.cfloat,
                 device='cpu'):
        """
        Args:
            params (Iterable): Iterable list of parameters
            lr (float): learning rate
            momentum (torch.cfloat): complex momentum value
            device (str, optional): device to run on. Defaults to 'cpu'.

        Returns:
            None
        """
        super().__init__(params, defaults = dict(lr=lr))
        self.momentum = torch.tensor(momentum)
        self.momentum.to(device)
        self.state = dict()
        for gr in self.param_groups:
            for p in gr['params']:
                self.state[p] = dict(velocity = torch.zeros_like(p,
                                                                 dtype=torch.cfloat,
                                                                 device=device))

    def step(self):
        for gr in self.param_groups:
            for p in gr['params']:
                self.state[p]['velocity'] = self.state[p]['velocity'] * self.momentum - p.grad
                p.data += (gr['lr'] * self.state[p]['velocity']).real
</code></pre><p>The advantage is that complex-momentum SGD offers a much more generic algorithm that is applicable to adversarial and non-adversarial (sometimes called <em>cooperative</em>) problems, and everything in between. Consider the following minmax objective.</p><p>$$ \underset{\vx}{\min} \; \underset{\vy}{\max} \; \vx^T(\lambda A)\vy + \vx^T((I - \lambda)B)\vx - \vy^T((I - \lambda)H)\vy $$<a id=eq:minmax-gen class=anchor></a></p><p>Where $A, B, H$ are coefficient matrices, and $\lambda$ controls the "adversarial-ness" of the objective. When $\lambda=0$, the first tem vanishes and $\vx$ and $\vy$ can be optimized independently. Thus, it becomes a purely cooperative objective. This is the regime where positive momentum works best. When $\lambda = I$, the above equation reduces to the first term and the problem becomes purely adversarial. For such problems, the complex-momentum SGD provides a one-stop solution.</p><h2>Conclusion</h2><p>The point of this discussion to shed some light on the usefulness of complex numbers in constructing a compact yet powerful representation of a more sophisticated procedure. In the above two examples, the complex representation did not solve any problem uniquely, but was shown to be equivalent to or a generalization of other standard procedures.</p><hr><p><table class=fndef id=fndef:1><tr><td class=fndef-backref><a href=#fnref:1>[1]</a></td><td class=fndef-content>Refer to this <a href=https://math.stackexchange.com/a/888280>stackexchange answer</a> for a derivation.</td></tr></table></p><p><table class=fndef id=fndef:2><tr><td class=fndef-backref><a href=#fnref:2>[2]</a></td><td class=fndef-content>Refer to chapter 3 of Griewank, A. and Walther, A., 2008. Evaluating derivatives: principles and techniques of algorithmic differentiation. SIAM.</td></tr></table></p><p><table class=fndef id=fndef:3><tr><td class=fndef-backref><a href=#fnref:3>[3]</a></td><td class=fndef-content>Examples of handling special control flows can be found in Martins et. al.'s <a href=https://hal.archives-ouvertes.fr/hal-01483287/document>paper</a>.</td></tr></table></p><p><table class=fndef id=fndef:adam><tr><td class=fndef-backref><a href=#fnref:adam>[4]</a></td><td class=fndef-content>The squared-gradient terms that you see in RMSProp, Adam etc, is basically an approximation of the local curvature (Hessian) of the loss landscape. These techniques adapt the learning rate using this local curvature, although from the way they are written in literature, one may think of them as modifying just the velocity factor.</td></tr></table></p><p><table class=fndef id=fndef:nag><tr><td class=fndef-backref><a href=#fnref:nag>[5]</a></td><td class=fndef-content>Nagarajan, Vaishnavh, and J. Zico Kolter. <em>Gradient descent GAN optimization is locally stable.</em> Advances in neural information processing systems 30 (2017).</td></tr></table></p><p><table class=fndef id=fndef:dirac><tr><td class=fndef-backref><a href=#fnref:dirac>[6]</a></td><td class=fndef-content>Mescheder, L., Geiger, A., &amp; Nowozin, S. (2018, July). <em>Which training methods for gans do actually converge?</em>. In International conference on machine learning (pp. 3481-3490). PMLR. <a href=https://arxiv.org/abs/1801.04406>ArXiv Link</a&lt;></tr></table></p><p><table class=fndef id=fndef:negmom><tr><td class=fndef-backref><a href=#fnref:negmom>[7]</a></td><td class=fndef-content>Gidel, G., Hemmat, R. A., Pezeshki, M., Le Priol, R., Huang, G., Lacoste-Julien, S., &amp; Mitliagkas, I. (2019, April). Negative momentum for improved game dynamics. In The 22nd International Conference on Artificial Intelligence and Statistics (pp. 1802-1811). PMLR. <a href=https://arxiv.org/abs/1807.04740>ArXiv Link</a&lt;></tr></table></p><p><table class=fndef id=fndef:complexsgd><tr><td class=fndef-backref><a href=#fnref:complexsgd>[8]</a></td><td class=fndef-content>Lorraine, J.P., et al. <em>Complex momentum for optimization in games.</em> International Conference on Artificial Intelligence and Statistics. PMLR, 2022. <a href=https://arxiv.org/abs/2102.08431>ArXiv Link</a&lt;></tr></table></p></main><div style="font-size:1.2rem; font-family: 'Overpass'; color: var(--c-4); text-align: center; margin-top: 6em; border-width: 75%; border-top: 1px solid var(--c-4); padding-top: 2em; margin-bottom: 4em;"> &copy; 2024 Anand K Subramanian <span class=vl></span><a href=/license>License</a> <span class=vl></span><a href=/design>Design</a> <span class=vl></span> Built with Kutti <span style="color: #e25555; font-size: 24px;">&hearts;</span></div><script src=/_libs/highlight/highlight.min.js></script><script>hljs.highlightAll(); hljs.configure({ tabReplace: '    ' });</script><link rel=stylesheet href=/_libs/highlight/decaf.css><script src=/_libs/clipboard/clipboard.min.js></script><script>
    (function () {

      // Get the elements.
      // - the 'pre' element.
      // - the 'div' with the 'paste-content' id.

      var pre = document.getElementsByTagName('pre');

      // Add a copy button in the 'pre' element.
      // which only has the className of 'language-'.

      for (var i = 0; i < pre.length; i++) {
        var isLanguage = pre[i].children[0].className.indexOf('language-');

        if (isLanguage === 0) {
          var button = document.createElement('button');
          button.className = 'copy-button';
          button.textContent = 'Copy';

          pre[i].appendChild(button);
        }
      };

      // Run Clipboard

      var copyCode = new Clipboard('.copy-button', {
        target: function (trigger) {
          return trigger.previousElementSibling;
        }
      });

      // On success:
      // - Change the "Copy" text to "Copied".
      // - Swap it to "Copy" in 2s.
      // - Lead user to the "contenteditable" area with Velocity scroll.

      copyCode.on('success', function (event) {
        event.clearSelection();
        event.trigger.textContent = 'Copied';
        window.setTimeout(function () {
          event.trigger.textContent = 'Copy';
        }, 2000);

      });

      // On error (Safari):
      // - Change the  "Press Ctrl+C to copy"
      // - Swap it to "Copy" in 2s.

      copyCode.on('error', function (event) {
        event.trigger.textContent = 'Press "Ctrl + C" to copy';
        window.setTimeout(function () {
          event.trigger.textContent = 'Copy';
        }, 5000);
      });

    })();
  </script></body></html>